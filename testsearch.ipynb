{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (10) does not match length of index (69)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Elle\\Desktop\\OneDrivePersonal\\OneDrive\\PersonalPythonProjects\\Hackathon2022\\DiscordData\\application\\coheresemanticsearchtool\\testsearch.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# run function to search for the query\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m test \u001b[39m=\u001b[39m search(\u001b[39m'\u001b[39;49m\u001b[39mhow to use cohere\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m10\u001b[39;49m, df, search_index, co)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m test\n",
      "\u001b[1;32mc:\\Users\\Elle\\Desktop\\OneDrivePersonal\\OneDrive\\PersonalPythonProjects\\Hackathon2022\\DiscordData\\application\\coheresemanticsearchtool\\testsearch.ipynb Cell 1\u001b[0m in \u001b[0;36msearch\u001b[1;34m(query, n_results, df, search_index, co)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Get the nearest neighbors and similarity score for the query and the embeddings, append it to the dataframe\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m nearest_neighbors \u001b[39m=\u001b[39m search_index\u001b[39m.\u001b[39mget_nns_by_vector(query_embed[\u001b[39m0\u001b[39m], n_results, include_distances\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nearest_neighbors[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mnearest_neighbors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nearest_neighbors[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Elle/Desktop/OneDrivePersonal/OneDrive/PersonalPythonProjects/Hackathon2022/DiscordData/application/coheresemanticsearchtool/testsearch.ipynb#W0sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:4529\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4528\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4529\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4530\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (10) does not match length of index (69)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cohere\n",
    "import time\n",
    "from annoy import AnnoyIndex\n",
    "co = cohere.Client('bE6Is3wvtmXyHtgnCQocDIgdH7PcYwdR21ZhnXgN') \n",
    "\n",
    "def embeddings(texts,sleep_time=5):\n",
    "    # add a wait time to simulate a long running process\n",
    "    time.sleep(sleep_time)\n",
    "    response = co.embed(\n",
    "        model='large',\n",
    "        texts=list(texts), \n",
    "        truncate='LEFT').embeddings\n",
    "    return response\n",
    "\n",
    "df = pd.read_excel('cohere_docs_embeddings.xlsx')\n",
    "\n",
    "def load_data(df,):\n",
    "    df['embeddings'] = embeddings(df['text'])\n",
    "    # drop rows frm text_df that havve less than 8 words\n",
    "    df = df[df['text'].str.split().str.len() > 10]\n",
    "    # Create the search index, pass the size of embedding\n",
    "    search_index = AnnoyIndex(4096, 'angular')\n",
    "    # Add all the vectors to the search index, these are stored in the dataframe 'post_members['embeddings']'\n",
    "    for i, vector in enumerate(df['embeddings']):\n",
    "        search_index.add_item(i, vector)\n",
    "    # Build the search index\n",
    "    search_index.build(10)\n",
    "    #save the search index\n",
    "    search_index.save('search_index.ann')\n",
    "    return df, search_index\n",
    "\n",
    "df, search_index = load_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<annoy.Annoy at 0x1794cf684f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elle\\AppData\\Local\\Temp\\ipykernel_14488\\1859625581.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['similarity'] = nearest_neighbors[1]\n",
      "C:\\Users\\Elle\\AppData\\Local\\Temp\\ipykernel_14488\\1859625581.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_neighbors'] = nearest_neighbors[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>similarity</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['This endpoint classifies text into one of se...</td>\n",
       "      <td>Toxicity Detectionpost</td>\n",
       "      <td>/reference/toxicity-detection</td>\n",
       "      <td>[0.0592041, -0.49951172, -0.72558594, 0.599121...</td>\n",
       "      <td>0.985209</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>['This endpoint generates realistic text condi...</td>\n",
       "      <td>Co.Generatepost</td>\n",
       "      <td>/reference/generate</td>\n",
       "      <td>[2.8222656, -0.94677734, 1.5234375, -0.8032226...</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['This endpoint classifies text into one of se...</td>\n",
       "      <td>/classify</td>\n",
       "      <td>/reference/toxicity-detection</td>\n",
       "      <td>[0.0592041, -0.49951172, -0.72558594, 0.599121...</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['When you call the Generate endpoint, you hav...</td>\n",
       "      <td>Number of Generations</td>\n",
       "      <td>/docs/number-of-generations</td>\n",
       "      <td>[1.7412109, -0.23046875, 0.6401367, -0.7202148...</td>\n",
       "      <td>0.880471</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>['This endpoint generates realistic text condi...</td>\n",
       "      <td>/generate</td>\n",
       "      <td>/reference/generate</td>\n",
       "      <td>[2.8222656, -0.94677734, 1.5234375, -0.8032226...</td>\n",
       "      <td>0.880471</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text                   title  \\\n",
       "68  ['This endpoint classifies text into one of se...  Toxicity Detectionpost   \n",
       "43  ['This endpoint generates realistic text condi...         Co.Generatepost   \n",
       "67  ['This endpoint classifies text into one of se...               /classify   \n",
       "12  ['When you call the Generate endpoint, you hav...   Number of Generations   \n",
       "42  ['This endpoint generates realistic text condi...               /generate   \n",
       "\n",
       "                             link  \\\n",
       "68  /reference/toxicity-detection   \n",
       "43            /reference/generate   \n",
       "67  /reference/toxicity-detection   \n",
       "12    /docs/number-of-generations   \n",
       "42            /reference/generate   \n",
       "\n",
       "                                           embeddings  similarity  \\\n",
       "68  [0.0592041, -0.49951172, -0.72558594, 0.599121...    0.985209   \n",
       "43  [2.8222656, -0.94677734, 1.5234375, -0.8032226...    0.959930   \n",
       "67  [0.0592041, -0.49951172, -0.72558594, 0.599121...    0.959930   \n",
       "12  [1.7412109, -0.23046875, 0.6401367, -0.7202148...    0.880471   \n",
       "42  [2.8222656, -0.94677734, 1.5234375, -0.8032226...    0.880471   \n",
       "\n",
       "    nearest_neighbors  \n",
       "68                 12  \n",
       "43                 67  \n",
       "67                 68  \n",
       "12                 42  \n",
       "42                 43  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query, n_results, df, search_index, co):\n",
    "    # Get the query's embedding\n",
    "    query_embed = co.embed(texts=[query],\n",
    "                    model=\"large\",\n",
    "                    truncate=\"LEFT\").embeddings\n",
    "\n",
    "    # Get the nearest neighbors and similarity score for the query and the embeddings, append it to the dataframe\n",
    "    nearest_neighbors = search_index.get_nns_by_vector(query_embed[0], n_results, include_distances=True)\n",
    "    # filter the dataframe to only include the nearest neighbors using the index\n",
    "    df = df[df.index.isin(nearest_neighbors[0])]\n",
    "    df['similarity'] = nearest_neighbors[1]\n",
    "    df['nearest_neighbors'] = nearest_neighbors[0]\n",
    "    df = df.sort_values(by='similarity', ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# run function to search for the query\n",
    "test = search('What are usage examples for the generate endpoint?', 5, df, search_index, co)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>similarity</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['This endpoint classifies text into one of se...</td>\n",
       "      <td>Toxicity Detectionpost</td>\n",
       "      <td>/reference/toxicity-detection</td>\n",
       "      <td>[0.0592041, -0.49951172, -0.72558594, 0.599121...</td>\n",
       "      <td>0.985209</td>\n",
       "      <td>12</td>\n",
       "      <td>\\n\\nThese are the training examples we give th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>['This endpoint generates realistic text condi...</td>\n",
       "      <td>Co.Generatepost</td>\n",
       "      <td>/reference/generate</td>\n",
       "      <td>[2.8222656, -0.94677734, 1.5234375, -0.8032226...</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>67</td>\n",
       "      <td>\\n\\nThe Generate endpoint generates text given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['This endpoint classifies text into one of se...</td>\n",
       "      <td>/classify</td>\n",
       "      <td>/reference/toxicity-detection</td>\n",
       "      <td>[0.0592041, -0.49951172, -0.72558594, 0.599121...</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>68</td>\n",
       "      <td>\\n\\nThe generate endpoint classifies text into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['When you call the Generate endpoint, you hav...</td>\n",
       "      <td>Number of Generations</td>\n",
       "      <td>/docs/number-of-generations</td>\n",
       "      <td>[1.7412109, -0.23046875, 0.6401367, -0.7202148...</td>\n",
       "      <td>0.880471</td>\n",
       "      <td>42</td>\n",
       "      <td>The generate endpoint can be used to generate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>['This endpoint generates realistic text condi...</td>\n",
       "      <td>/generate</td>\n",
       "      <td>/reference/generate</td>\n",
       "      <td>[2.8222656, -0.94677734, 1.5234375, -0.8032226...</td>\n",
       "      <td>0.880471</td>\n",
       "      <td>43</td>\n",
       "      <td>\\n\\nThe Generate endpoint generates text given...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text                   title  \\\n",
       "68  ['This endpoint classifies text into one of se...  Toxicity Detectionpost   \n",
       "43  ['This endpoint generates realistic text condi...         Co.Generatepost   \n",
       "67  ['This endpoint classifies text into one of se...               /classify   \n",
       "12  ['When you call the Generate endpoint, you hav...   Number of Generations   \n",
       "42  ['This endpoint generates realistic text condi...               /generate   \n",
       "\n",
       "                             link  \\\n",
       "68  /reference/toxicity-detection   \n",
       "43            /reference/generate   \n",
       "67  /reference/toxicity-detection   \n",
       "12    /docs/number-of-generations   \n",
       "42            /reference/generate   \n",
       "\n",
       "                                           embeddings  similarity  \\\n",
       "68  [0.0592041, -0.49951172, -0.72558594, 0.599121...    0.985209   \n",
       "43  [2.8222656, -0.94677734, 1.5234375, -0.8032226...    0.959930   \n",
       "67  [0.0592041, -0.49951172, -0.72558594, 0.599121...    0.959930   \n",
       "12  [1.7412109, -0.23046875, 0.6401367, -0.7202148...    0.880471   \n",
       "42  [2.8222656, -0.94677734, 1.5234375, -0.8032226...    0.880471   \n",
       "\n",
       "    nearest_neighbors                                             answer  \n",
       "68                 12  \\n\\nThese are the training examples we give th...  \n",
       "43                 67  \\n\\nThe Generate endpoint generates text given...  \n",
       "67                 68  \\n\\nThe generate endpoint classifies text into...  \n",
       "12                 42   The generate endpoint can be used to generate...  \n",
       "42                 43  \\n\\nThe Generate endpoint generates text given...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_answer(q, para): \n",
    "    response = co.generate( \n",
    "        model='command-xlarge-20221108', \n",
    "        prompt=f'Paragraph:{para}\\n\\nAnswer the question using this paragraph.\\n\\nQuestion: {q}\\nAnswer:', \n",
    "        max_tokens=100, \n",
    "        temperature=0.4, \n",
    "        k=0, \n",
    "        p=0.75, \n",
    "        frequency_penalty=0, \n",
    "        presence_penalty=0, \n",
    "        stop_sequences=[], \n",
    "        return_likelihoods='NONE') \n",
    "    return response.generations[0].text\n",
    "\n",
    "# for each row in the dataframe, generate an answer\n",
    "test['answer'] = test.apply(lambda x: gen_answer('What are usage examples for the generate endpoint?', x['text']), axis=1)\n",
    "test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are usage examples for the generate endpoint?\n",
      "Answer:  \n",
      "\n",
      "These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.\n",
      "Similarity:  0.9852094054222107\n",
      "Paragraph:  ['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'The internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.', 'Here we look at an example of classifying online user comments for toxicity by classifying them in Toxic or Not Toxic.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']\n",
      "-----------------------------\n",
      "Question: What are usage examples for the generate endpoint?\n",
      "Answer:  \n",
      "\n",
      "The Generate endpoint generates text given an input, called a prompt. The prompt provides a context for the text that we want the model to generate. Prompt engineering is a fascinating topic. It is about figuring out the optimal way to prompt a model for a particular task, so we can shape the output to be how we want it to be. In this example, we have a startup idea generator. We want the endpoint to generate a startup idea and its name, given an industry/\n",
      "Similarity:  0.9599300622940063\n",
      "Paragraph:  ['This endpoint generates realistic text conditioned on a given input.', 'The Generate endpoint generates text given an input, called a prompt. The prompt provides a context for the text that we want the model to generate.', 'Prompt engineering is a fascinating topic. It is about figuring out the optimal way to prompt a model for a particular task, so we can shape the output to be how we want it to be.', 'In this example, we have a startup idea generator. We want the endpoint to generate a startup idea and its name, given an industry/vertical as the input.', \"Install the SDK, if you haven't already.\", 'Next, set up the Cohere client.', 'A basic prompt format that generally works well contains: ', 'The Generate endpoint has a number of settings we can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:\\nmodel - Either medium or xlarge. Generally, smaller models are faster while larger models will perform better.\\nmax_tokens - The maximum length of text to be generated. One word contains approximately 2-3 tokens.\\ntemperature - Ranges from 0 to 5. Controls the randomness of the output. Lower values tend to generate more “predictable” output, while higher values tend to generate more “creative” output. The sweet spot is typically between 0 and 1.\\nstop_sequences - A stop sequence will cut off your generation at the end of the sequence. This effectively informs the model of when to stop. Add your stop sequence at the end of each example in the prompt (refer to the prompt we’d created, which uses “--” as the stop sequence).', 'Call the Generate endpoint via the co.generate() method, specifying the prompt and the rest of the model settings.']\n",
      "-----------------------------\n",
      "Question: What are usage examples for the generate endpoint?\n",
      "Answer:  \n",
      "\n",
      "The generate endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.\n",
      "Similarity:  0.9599300622940063\n",
      "Paragraph:  ['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'The internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.', 'Here we look at an example of classifying online user comments for toxicity by classifying them in Toxic or Not Toxic.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']\n",
      "-----------------------------\n",
      "Question: What are usage examples for the generate endpoint?\n",
      "Answer:   The generate endpoint can be used to generate multiple generations in a single call, which is done by setting the num_generations parameter. This can be used in a number of ways, for example, by selecting the one with the highest likelihood as the final output or by presenting these as options in your application.\n",
      "Similarity:  0.8804709911346436\n",
      "Paragraph:  ['When you call the Generate endpoint, you have the option to generate multiple generations in a single call. This is done by setting the num_generations parameter.', 'Generating multiple outputs in a single API call.', 'The model’s outputs will vary depending on the generation settings you have specified, such as temperature, top-k, and top-p.', 'Each generation comes with its set of likelihood values, which consists of:', 'This example uses the input: “This curved gaming monitor delivers ...”', 'The output generated with a maximum token set of 4 and sorted by average token likelihood are:', 'You can use these outputs in a number of ways, for example, by selecting the one with the highest likelihood as the final output or by presenting these as options in your application.', 'Updated about 1 month ago ']\n",
      "-----------------------------\n",
      "Question: What are usage examples for the generate endpoint?\n",
      "Answer:  \n",
      "\n",
      "The Generate endpoint generates text given an input, called a prompt. The prompt provides a context for the text that we want the model to generate. Prompt engineering is a fascinating topic. It is about figuring out the optimal way to prompt a model for a particular task, so we can shape the output to be how we want it to be. In this example, we have a startup idea generator. We want the endpoint to generate a startup idea and its name, given an industry/\n",
      "Similarity:  0.8804709911346436\n",
      "Paragraph:  ['This endpoint generates realistic text conditioned on a given input.', 'The Generate endpoint generates text given an input, called a prompt. The prompt provides a context for the text that we want the model to generate.', 'Prompt engineering is a fascinating topic. It is about figuring out the optimal way to prompt a model for a particular task, so we can shape the output to be how we want it to be.', 'In this example, we have a startup idea generator. We want the endpoint to generate a startup idea and its name, given an industry/vertical as the input.', \"Install the SDK, if you haven't already.\", 'Next, set up the Cohere client.', 'A basic prompt format that generally works well contains: ', 'The Generate endpoint has a number of settings we can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:\\nmodel - Either medium or xlarge. Generally, smaller models are faster while larger models will perform better.\\nmax_tokens - The maximum length of text to be generated. One word contains approximately 2-3 tokens.\\ntemperature - Ranges from 0 to 5. Controls the randomness of the output. Lower values tend to generate more “predictable” output, while higher values tend to generate more “creative” output. The sweet spot is typically between 0 and 1.\\nstop_sequences - A stop sequence will cut off your generation at the end of the sequence. This effectively informs the model of when to stop. Add your stop sequence at the end of each example in the prompt (refer to the prompt we’d created, which uses “--” as the stop sequence).', 'Call the Generate endpoint via the co.generate() method, specifying the prompt and the rest of the model settings.']\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# for each row print the question, paragraph, and answer\n",
    "for index, row in test.iterrows():\n",
    "    print('Question: What are usage examples for the generate endpoint?')\n",
    "    print('Answer: ', row['answer'])\n",
    "    print('Similarity: ', row['similarity'])\n",
    "    print('Paragraph: ', row['text'])\n",
    "\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae14b38ed1332e198343df287833618bb240460acf309fe3913e8dcb7acd28b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
